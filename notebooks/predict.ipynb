{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/airobot/airobots/ObjectDetection/AiRobot_WAD_Video_Segmentation\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.3\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "EPSILON                        1e-08\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  3584\n",
      "IMAGE_META_SIZE                20\n",
      "IMAGE_MIN_DIM                  2048\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              none\n",
      "IMAGE_SHAPE                    [2048 3584    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [88.59672608 95.91837699 98.90089033]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           Adriving\n",
      "NUM_CLASSES                    8\n",
      "OPTIMIZER                      SGD\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        2000\n",
      "POST_NMS_ROIS_TRAINING         4000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.6\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    320\n",
      "STEPS_PER_EPOCH                1200\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           500\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "# 获取项目根目录\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "sys.path.append(ROOT_DIR)\n",
    "print (ROOT_DIR)\n",
    "#print (sys.path)\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from pathlib import PureWindowsPath as Path\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"maskrcnn/\"))\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "from mrcnn import model as modellib\n",
    "from mrcnn.model import log\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "from mrcnn.config import Config\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from adriving_util import *\n",
    "\n",
    "os.environ[\"TF_MIN_GPU_MULTIPROCESSOR_COUNT\"] = \"4\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "image_size = (2048, 3584)\n",
    "settingsDir = os.path.join(ROOT_DIR,'settings.json')\n",
    "with open(settingsDir) as f:\n",
    "    setting = json.load(f)\n",
    "\n",
    "class AdrivingConfig(Config):\n",
    "    NAME = \"Adriving\"\n",
    "    IMAGES_PER_GPU = 1\n",
    "    NUM_CLASSES = 1 + 7 \n",
    "    STEPS_PER_EPOCH = 1200\n",
    "    RPN_NMS_THRESHOLD = 0.60\n",
    "    TRAIN_ROIS_PER_IMAGE = 500\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 320\n",
    "    POST_NMS_ROIS_TRAINING = 4000\n",
    "    POST_NMS_ROIS_INFERENCE = 2000\n",
    "    IMAGE_MIN_DIM = image_size[0]\n",
    "    IMAGE_MAX_DIM = image_size[1]\n",
    "    IMAGE_RESIZE_MODE = \"none\"\n",
    "    MEAN_PIXEL = np.array([88.59672608, 95.91837699, 98.90089033])\n",
    "    DETECTION_MIN_CONFIDENCE = 0.3\n",
    "\n",
    "\n",
    "config = AdrivingConfig()\n",
    "class InferenceConfig(config.__class__):\n",
    "    # Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "config = InferenceConfig()\n",
    "config.display()\n",
    "DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "import mrcnn.utils as utils\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "from skimage import data, img_as_float\n",
    "from skimage import exposure\n",
    "\n",
    "def crop_and_resize_test(image, contrast = False):\n",
    "    img_crop = np.zeros([image_size[0], image_size[1], 3], dtype = np.float)\n",
    "    img_roi = image[-image_size[0]:, :, :]\n",
    "    if contrast:\n",
    "        img_adapteq = exposure.equalize_adapthist(img_roi, clip_limit=0.01)\n",
    "    else:\n",
    "        img_adapteq = img_roi / 255.0\n",
    "    img_adapteq = img_adapteq * 255.0\n",
    "    img_crop[:, 72:(72+3384), :] = img_adapteq\n",
    "    return img_crop\n",
    "\n",
    "\n",
    "def load_test_image(image_filename, test_dir):\n",
    "    if os.path.islink(str(test_dir/image_filename)):\n",
    "        image_path = os.readlink(test_dir/image_filename)\n",
    "    else:\n",
    "        image_path = str(test_dir/image_filename)\n",
    "\n",
    "    image = skimage.io.imread(image_path)\n",
    "    image = crop_and_resize_test(image)\n",
    "    return image\n",
    "\n",
    "from scipy import sparse\n",
    "def prediction_to_sparse(prediction):\n",
    "    prediction_sparse = dict()\n",
    "    prediction_sparse['rois'] = prediction['rois']\n",
    "    prediction_sparse['class_ids'] = prediction['class_ids']\n",
    "    prediction_sparse['scores'] = prediction['scores']\n",
    "\n",
    "    prediction_sparse['masks'] = []\n",
    "    for i in range(len(prediction['scores'])):\n",
    "        prediction_sparse['masks'].append(sparse.bsr_matrix(prediction['masks'][:, :, i]))\n",
    "    return prediction_sparse\n",
    "\n",
    "\n",
    "def predict(model, test_image, test_dir, results_folder, write_rle = True):\n",
    "    file_name = results_folder + '.txt'\n",
    "    if write_rle:\n",
    "        with open(file_name, 'w+') as prediction_file:\n",
    "            prediction_file.write('ImageId,LabelId,Confidence,PixelCount,EncodedPixels\\n')\n",
    "\n",
    "    for image_filename in tqdm(test_image, ncols = 50):\n",
    "        image = load_test_image(image_filename, test_dir)\n",
    "        image_id = image_filename[:-4]\n",
    "        prediction = model.detect([image], verbose=0)[0]\n",
    "        if len(prediction['class_ids']) == 0:\n",
    "            with open(file_name, 'a+') as prediction_file:\n",
    "                prediction_file.write(image_id + ',' + '33,300,1,0 100|0 100|0 100|\\n')\n",
    "            continue\n",
    "        prediction_sparse = prediction_to_sparse(prediction)\n",
    "        with open(results_folder + '/' + image_id + '.p', 'wb') as f:\n",
    "            pickle.dump(prediction_sparse, f)\n",
    "        if write_rle:\n",
    "            with open(file_name, 'a+') as prediction_file:\n",
    "                mask_pred = np.zeros([2710, 3384, len(prediction['scores'])], dtype = bool)\n",
    "                mask_pred[-image_size[0]:, :, :] = prediction['masks'][:, 72:(72+3384), :]\n",
    "                mask, instance_score = instance_to_mask(mask_pred, prediction['class_ids'],\n",
    "                                                          prediction['scores'])\n",
    "                rle_string_list =  write_mask(image_id, mask, score = instance_score)\n",
    "                for rle_str in rle_string_list:\n",
    "                    prediction_file.write(rle_str)\n",
    "                    prediction_file.write('\\n')\n",
    "\n",
    "\n",
    "\n",
    "def predict_rle(model, test_image, test_dir, file_name):\n",
    "    with open(file_name, 'w') as prediction_file:\n",
    "         prediction_file.write('ImageId,LabelId,Confidence,PixelCount,EncodedPixels\\n')\n",
    "            \n",
    "    with open(file_name, 'a') as prediction_file:\n",
    "        for image_filename in tqdm(test_image, ncols = 40):\n",
    "            image = load_test_image(image_filename, test_dir)\n",
    "            image_id = image_filename[:-4]\n",
    "            prediction = model.detect([image], verbose=0)[0]\n",
    "            if len(prediction['class_ids']) == 0:\n",
    "                with open(file_name, 'a+') as predictionfile:\n",
    "                    predictionfile.write(image_id + ',' + '33,300,1,0 100|0 100|0 100|\\n')\n",
    "                continue\n",
    "            mask, score = instance_to_mask(prediction['masks'], prediction['class_ids'], score = prediction['scores'])\n",
    "            mask_original = np.zeros([2710, 3384], dtype = np.int)\n",
    "            mask_original[-image_size[0]:, :] = mask[:, 72:(72+3384)]\n",
    "            rle_string_list =  write_mask(image_id, mask_original, score = score)\n",
    "            for rle_str in rle_string_list:\n",
    "                prediction_file.write(rle_str)\n",
    "                prediction_file.write('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights  /media/airobot/airobots/ObjectDetection/AiRobot_WAD_Video_Segmentation/./models/mask_rcnn_adriving_0006.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▉             | 3/43 [00:09<02:44,  4.11s/it]/home/airobot/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "100%|█████████████| 43/43 [00:59<00:00,  1.22s/it]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    mode = 'test'\n",
    "    if mode == 'test':\n",
    "        test_dir = Path(os.path.join(ROOT_DIR,setting['TEST_DATA_CLEAN_PATH'], \"test2\"))\n",
    "    else:\n",
    "        test_dir = Path('../../data/train_full/val/image')\n",
    "\n",
    "    test_image = os.listdir(str(test_dir))\n",
    "    test_image = [x for x in test_image if x[0] != '.']\n",
    "    test_image.sort()\n",
    "    if mode == 'val':\n",
    "        test_image = test_image[:100]\n",
    "\n",
    "    MODEL_DIR = 'log'\n",
    "    # with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
    "                              config=config)\n",
    "\n",
    "    weights_path = os.path.join(ROOT_DIR, \n",
    "                                setting['MODEL_CHECKPOINT_DIR'], \n",
    "                                'mask_rcnn_adriving_0006.h5')\n",
    "\n",
    "    print(\"Loading weights \", weights_path)\n",
    "    model.load_weights(weights_path, by_name=True)\n",
    "    #time = time.strftime(\"%Y%m%d%H%M%S\", time.localtime())\n",
    "    results_folder = os.path.join(ROOT_DIR, \n",
    "                                  setting['RESULTS_DIR'], \n",
    "                                  'submit/201812232125')\n",
    "    os.makedirs(results_folder)\n",
    "    predict(model, test_image, test_dir, results_folder)\n",
    "    #最终输出\n",
    "    with open(results_folder+'.txt', 'r') as txtR:\n",
    "        in_txt = csv.reader(txtR,delimiter = ',',escapechar='\\n')\n",
    "        with open(results_folder+'.csv', 'w') as csvR:\n",
    "            out_csv = csv.writer(csvR)\n",
    "            out_csv.writerows(in_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
